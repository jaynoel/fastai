{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of lesson6-rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "0hf8JMYzsLSi",
        "bl_vNDIjsLUJ",
        "dKN4ew-XsLVu",
        "t_efbtxFsLWd",
        "KInwcsSzsLYb",
        "ylq6LSkKsLaz",
        "yN3etRs_sLcz",
        "3mqQOcomsLdt",
        "xG7H7r-xsLfn",
        "qt7rgEuSsLgv",
        "19sGuyRksLhg",
        "tnsVZkjusLh0",
        "X-0kBDWVsLia",
        "-EMhG0GqsLi_",
        "5AA7XqYesLjy",
        "0p9lUNJssLk6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaynoel/fastai/blob/master/Copy_of_lesson6_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MKxmjEN2sLPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#\n",
        "#    revision history to repo in jaynoel\n",
        "#\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai.io import *\n",
        "from fastai.conv_learner import *\n",
        "\n",
        "from fastai.column_data import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EIMVqIRusLQB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "3KT0t5fFsLQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going to download the collected works of Nietzsche to use as our data for this class."
      ]
    },
    {
      "metadata": {
        "id": "ZmtoG6ihsLQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH='data/nietzsche/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWEPkXSlsLQT",
        "colab_type": "code",
        "outputId": "c572a0fc-4f44-4e72-f148-5feac86a778a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
        "text = open(f'{PATH}nietzsche.txt').read()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HuDux5m4sLQ1",
        "colab_type": "code",
        "outputId": "ce75f0e9-b6a7-47c4-8a67-57c0a744731b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text[:400]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to Truth, have been unskilled and unseemly methods for\\nwinning a woman? Certainly she has never allowed herself '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "ypYEuSIXsLRT",
        "colab_type": "code",
        "outputId": "a5f6c626-0040-406c-aca8-b4021999afaa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)+1\n",
        "print('total chars:', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9fLRUnSsLRm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sometimes it's useful to have a zero value in the dataset, e.g. for padding"
      ]
    },
    {
      "metadata": {
        "id": "JGwKdAOrsLRr",
        "colab_type": "code",
        "outputId": "3c9f5577-469f-4d21-ba6c-eaf3c9c077b6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars.insert(0, \"\\0\")\n",
        "\n",
        "''.join(chars[1:-6])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "ffsCfyc8sLR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Map from chars to indices and back again"
      ]
    },
    {
      "metadata": {
        "id": "4b1ArK0QsLR_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_indices = {c: i for i, c in enumerate(chars)}\n",
        "indices_char = {i: c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDusnvi7sLSH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*idx* will be the data we use from now on - it simply converts all the characters to their index (based on the mapping above)"
      ]
    },
    {
      "metadata": {
        "id": "sJ0PDkSBsLSK",
        "colab_type": "code",
        "outputId": "a2a46183-2ab9-4aa7-eb4f-4bf586098b08",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = [char_indices[c] for c in text]\n",
        "\n",
        "idx[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "HKe6fWwjsLSU",
        "colab_type": "code",
        "outputId": "d6019246-6e06-4ff6-da89-fadf26a18d1d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''.join(indices_char[i] for i in idx[:70])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "-hbC2_Q0sLSf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Three char model"
      ]
    },
    {
      "metadata": {
        "id": "0hf8JMYzsLSi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create inputs"
      ]
    },
    {
      "metadata": {
        "id": "Bo7NtOhRsLSl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
      ]
    },
    {
      "metadata": {
        "id": "EjX7OO04sLSp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=3\n",
        "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
        "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
        "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
        "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHwHzXz9sLSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our inputs"
      ]
    },
    {
      "metadata": {
        "id": "cAI_DLuYsLS2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = np.stack(c1_dat)\n",
        "x2 = np.stack(c2_dat)\n",
        "x3 = np.stack(c3_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rqx7E0OwsLTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our output"
      ]
    },
    {
      "metadata": {
        "id": "RbRzcjcEsLTF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.stack(c4_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jeXwPDkysLTQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first 4 inputs and outputs"
      ]
    },
    {
      "metadata": {
        "id": "LeP2ZwhxsLTV",
        "colab_type": "code",
        "outputId": "bad4c8b8-5622-4088-e959-12f480a2a82a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1[:4], x2[:4], x3[:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "ygp33vVfsLTp",
        "colab_type": "code",
        "outputId": "efb8c27e-6ae6-478c-ee63-1ab2bec9fa69",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y[:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30, 29,  1, 40])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "YXe1XDIosLT8",
        "colab_type": "code",
        "outputId": "8161db02-44de-4b36-ddde-0e1a0e99bf57",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((200295,), (200295,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "bl_vNDIjsLUJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "OHhdW2lWsLUO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pick a size for our hidden state"
      ]
    },
    {
      "metadata": {
        "id": "9fIrVccasLUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqbeuPl7sLUb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The number of latent factors to create (i.e. the size of the embedding matrix)"
      ]
    },
    {
      "metadata": {
        "id": "0vp9JIUpsLUc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_fac = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGeEphFPsLUk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Char3Model(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "\n",
        "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
        "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
        "\n",
        "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        \n",
        "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, c1, c2, c3):\n",
        "        in1 = F.relu(self.l_in(self.e(c1)))\n",
        "        in2 = F.relu(self.l_in(self.e(c2)))\n",
        "        in3 = F.relu(self.l_in(self.e(c3)))\n",
        "        \n",
        "        h = V(torch.zeros(in1.size()).cuda())\n",
        "        h = F.tanh(self.l_hidden(h+in1))\n",
        "        h = F.tanh(self.l_hidden(h+in2))\n",
        "        h = F.tanh(self.l_hidden(h+in3))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E24Q1Z06sLUq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUzdFM8tsLUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = Char3Model(vocab_size, n_fac).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42C5fbB0sLU9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = m(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TTIxoOBbsLVE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "on_dYku5sLVN",
        "colab_type": "code",
        "outputId": "78509866-37f8-4576-8075-269eb1c615b8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73483a3ac1804c3e81c8de6744d5c4bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       2.09627  6.52849]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-AORJGQFsLVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlVkToqQsLVf",
        "colab_type": "code",
        "outputId": "409c4b39-43eb-4e6a-8867-40f6045f43ae",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7278ec0864e451795d91bac0ff944c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.84525  6.52312]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dKN4ew-XsLVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "id": "SOzhfFQjsLVy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UXIoxb9_sLV7",
        "colab_type": "code",
        "outputId": "ca339c9a-ee70-4ee4-8687-325a4550e859",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('y. ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "PotkDmGMsLWC",
        "colab_type": "code",
        "outputId": "f203948e-afec-4c10-b0a1-a1d218caa70b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('ppl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "I1mKyiDTsLWK",
        "colab_type": "code",
        "outputId": "c7064908-ee57-4439-8925-66eff173a0e9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next(' th')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "w7X_0vp3sLWQ",
        "colab_type": "code",
        "outputId": "ed927731-da84-4fff-cec5-5bd8b312c471",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('and')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "SR6s5FKZsLWa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Our first RNN!"
      ]
    },
    {
      "metadata": {
        "id": "t_efbtxFsLWd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create inputs"
      ]
    },
    {
      "metadata": {
        "id": "0djJ4B5zsLWi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the size of our unrolled RNN."
      ]
    },
    {
      "metadata": {
        "id": "xDkmFzussLWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhhWt2IvsLWx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
      ]
    },
    {
      "metadata": {
        "id": "2phsqmC3sLW6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ibb6WprDsLXD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then create a list of the next character in each of these series. This will be the labels for our model."
      ]
    },
    {
      "metadata": {
        "id": "bkNMDB6AsLXG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JeGyYZaNsLXR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kw08fatOsLXl",
        "colab_type": "code",
        "outputId": "fec5175d-f09a-41e4-e697-db8b2842cc23",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600884, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "BzEMeq0usLXx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.stack(c_out_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNCoSfcwsLX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So each column below is one series of 8 characters from the text."
      ]
    },
    {
      "metadata": {
        "id": "oT2HM3ufsLYB",
        "colab_type": "code",
        "outputId": "d03684e3-7a45-44fe-e854-5a16aac405c8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs[:cs,:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
              "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
              "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
              "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
              "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
              "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
              "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
              "       [ 1,  1,  1, 43, 45, 40, 40, 39]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "AHP1zvb6sLYM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...and this is the next character after each sequence."
      ]
    },
    {
      "metadata": {
        "id": "STM6ARAGsLYO",
        "colab_type": "code",
        "outputId": "fa6a1b63-7f63-4a20-b82f-48f5cc5ce878",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y[:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1, 43, 45, 40, 40, 39, 43])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "KInwcsSzsLYb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "_R7q_nXDsLYe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(idx)-cs-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMjTjK5KsLYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzIWP4l1sLY4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharLoopModel(nn.Module):\n",
        "    # This is an RNN!\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = F.relu(self.l_in(self.e(c)))\n",
        "            h = F.tanh(self.l_hidden(h+inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtC4OH55sLZA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharLoopModel(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oIfW6qZqsLZI",
        "colab_type": "code",
        "outputId": "84affc60-b2d6-4cfe-9da2-10e7fa301d7b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d1c8fb012c74fe191921d467c80b5ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       2.02986  1.99268]                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "155G4DyYsLZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7MxlNHesLZl",
        "colab_type": "code",
        "outputId": "b488ef8d-6148-4b53-bc37-0a7c786b35be",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e4a151c0f274c129e346a22fd4bdece",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.73588  1.75103]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qm-sNzVssLZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharLoopConcatModel(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = torch.cat((h, self.e(c)), 1)\n",
        "            inp = F.relu(self.l_in(inp))\n",
        "            h = F.tanh(self.l_hidden(inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ovb1J1lgsLaB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DP69BKcqsLaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = m(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nCorPUYysLaT",
        "colab_type": "code",
        "outputId": "a17ff2cf-9c72-4b56-eece-02f961020fa4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1b3572e787441d8b2e5d80317245596",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.81654  1.78501]                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xM5e9i7TsLac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKQyMbgysLar",
        "colab_type": "code",
        "outputId": "62fda266-4945-4ba4-d494-c8f67a139b79",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aa67fbb4a2f42509dbe7753bc86d9a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.69008  1.69936]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ylq6LSkKsLaz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "id": "9uejE5lMsLa1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvdbWTRwsLa7",
        "colab_type": "code",
        "outputId": "7ff80193-119f-4a12-e0ee-410a1b8b0d35",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "cagITIrtsLbC",
        "colab_type": "code",
        "outputId": "33cc1046-750c-4b66-b2a1-aaaaa0766b81",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('part of ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "GoxxzuzTsLbR",
        "colab_type": "code",
        "outputId": "143c085c-a7e2-415d-b1e8-d8b41a1b1889",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('queens a')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "x3P2hX-nsLbZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN with pytorch"
      ]
    },
    {
      "metadata": {
        "id": "Xio3JgRIsLbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        \n",
        "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uedYY6DusLbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2mtFUxusLbq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXllj66rsLbu",
        "colab_type": "code",
        "outputId": "e7d8db6d-45b4-4927-b8f9-0392ff987d67",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = m.e(V(torch.stack(xs)))\n",
        "t.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 512, 42])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "kCDNrDjRsLb2",
        "colab_type": "code",
        "outputId": "f80eabae-66ef-413a-fd7c-47d3cb7ef982",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ht = V(torch.zeros(1, 512,n_hidden))\n",
        "outp, hn = m.rnn(t, ht)\n",
        "outp.size(), hn.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "9Kjq8YeEsLb9",
        "colab_type": "code",
        "outputId": "59b113bb-0d73-434e-8794-817515998fe6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = m(*V(xs)); t.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 85])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "VpUJ4SnQsLcP",
        "colab_type": "code",
        "outputId": "b0a99cd8-3ff4-4c19-d65b-45afee354f68",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "497078d15ec348149442681039df2e50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.86065  1.84255]                                 \n",
            "[ 1.       1.68014  1.67387]                                 \n",
            "[ 2.       1.58828  1.59169]                                 \n",
            "[ 3.       1.52989  1.54942]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "roIgfT6OsLcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNJYLhT8sLco",
        "colab_type": "code",
        "outputId": "7e0b8b29-12fe-47e8-bae1-cfec013dc474",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 2, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65a2f7bedaa34de2a40296a07387c1c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.46841  1.50966]                                 \n",
            "[ 1.       1.46482  1.5039 ]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yN3etRs_sLcz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "id": "wicHMxAAsLc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y0llQzw-sLdE",
        "colab_type": "code",
        "outputId": "9b28c781-c44a-41d8-dfcc-6f87d808a5f8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "RvtI2HsJsLdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0gUyNNcBsLdS",
        "colab_type": "code",
        "outputId": "53630956-b439-4b17-86e6-f69ec22a7d36",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next_n('for thos', 40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for those the same the same the same the same th'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "y-uvfLSzsLdk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi-output model"
      ]
    },
    {
      "metadata": {
        "id": "3mqQOcomsLdt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "id": "AfAIhdSjsLdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take non-overlapping sets of characters this time"
      ]
    },
    {
      "metadata": {
        "id": "ss3aHFuqsLeB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIPKal0BsLeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then create the exact same thing, offset by 1, as our labels"
      ]
    },
    {
      "metadata": {
        "id": "pQfrACo_sLeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aIIc7ONTsLek",
        "colab_type": "code",
        "outputId": "0dfca057-ec0e-46d3-d66e-b0d4f6b90c51",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat)\n",
        "xs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75111, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "9D4U-0jlsLe1",
        "colab_type": "code",
        "outputId": "98df104a-b714-4dae-d355-9245283ade27",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ys = np.stack(c_out_dat)\n",
        "ys.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75111, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "nOwdA-wjsLfL",
        "colab_type": "code",
        "outputId": "bb9a0cba-bc39-43dd-a32e-ca3aae023b03",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs[:cs,:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
              "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
              "       [33, 38, 31,  2, 73, 61, 54, 73],\n",
              "       [ 2, 44, 71, 74, 73, 61,  2, 62],\n",
              "       [72,  2, 54,  2, 76, 68, 66, 54],\n",
              "       [67,  9,  9, 76, 61, 54, 73,  2],\n",
              "       [73, 61, 58, 67, 24,  2, 33, 72],\n",
              "       [ 2, 73, 61, 58, 71, 58,  2, 67]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "wiNIP9Q3sLfg",
        "colab_type": "code",
        "outputId": "772e69e1-0d8c-4304-c3e6-ae76ab34582e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ys[:cs,:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[42, 29, 30, 25, 27, 29,  1,  1],\n",
              "       [ 1, 43, 45, 40, 40, 39, 43, 33],\n",
              "       [38, 31,  2, 73, 61, 54, 73,  2],\n",
              "       [44, 71, 74, 73, 61,  2, 62, 72],\n",
              "       [ 2, 54,  2, 76, 68, 66, 54, 67],\n",
              "       [ 9,  9, 76, 61, 54, 73,  2, 73],\n",
              "       [61, 58, 67, 24,  2, 33, 72,  2],\n",
              "       [73, 61, 58, 71, 58,  2, 67, 68]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "xG7H7r-xsLfn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "qJq7OaiHsLfp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(xs)-cs-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6SyfcZ1TsLfw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUz_qSK_sLf3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "byHZq6jlsLf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_NfZQS7hsLgE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xst,yt = next(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IoYiVs0msLgO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nll_loss_seq(inp, targ):\n",
        "    sl,bs,nh = inp.size()\n",
        "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
        "    return F.nll_loss(inp.view(-1,nh), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oSYSjIFQsLgb",
        "colab_type": "code",
        "outputId": "5a801ac4-1fde-40ca-a7f1-38b595c71e62",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "725ca331d28b482e9c7a4f83f741498e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       2.59241  2.40251]                                \n",
            "[ 1.       2.28474  2.19859]                                \n",
            "[ 2.       2.13883  2.08836]                                \n",
            "[ 3.       2.04892  2.01564]                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wpA7B8Y5sLgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4UMm7grsLgo",
        "colab_type": "code",
        "outputId": "90d7e282-3ed7-4467-db01-67671bc70125",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adb9aa22524d4bfd8b001d2efd10dbc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.99819  2.00106]                               \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qt7rgEuSsLgv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Identity init!"
      ]
    },
    {
      "metadata": {
        "id": "ZJZxnDlusLgw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UimFQkArsLg4",
        "colab_type": "code",
        "outputId": "2daa174f-2919-43a4-9d10-8ade3db214f9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    1     0     0  ...      0     0     0\n",
              "    0     1     0  ...      0     0     0\n",
              "    0     0     1  ...      0     0     0\n",
              "       ...          ⋱          ...       \n",
              "    0     0     0  ...      1     0     0\n",
              "    0     0     0  ...      0     1     0\n",
              "    0     0     0  ...      0     0     1\n",
              "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "EkVMhT1XsLg_",
        "colab_type": "code",
        "outputId": "e85a001e-4194-4152-fc58-75c0ebd58274",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e141251f24d4083a6e8b2fa15dea724",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       2.39428  2.21111]                                \n",
            "[ 1.       2.10381  2.03275]                                \n",
            "[ 2.       1.99451  1.96393]                               \n",
            "[ 3.       1.93492  1.91763]                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "twfJ0PwSsLhJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Ns2ntxTsLhR",
        "colab_type": "code",
        "outputId": "633ac69d-9bf8-444f-9a33-df5b32f286be",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddf833e8b7ec4a3aa29dd271911f76ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.84035  1.85742]                                \n",
            "[ 1.       1.82896  1.84887]                                \n",
            "[ 2.       1.81879  1.84281]                               \n",
            "[ 3.       1.81337  1.83801]                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "90AUQWFOsLhe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stateful model"
      ]
    },
    {
      "metadata": {
        "id": "19sGuyRksLhg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "id": "GC1vP8idsLhh",
        "colab_type": "code",
        "outputId": "d2bd3a08-84cf-42c1-e0f4-34ed1e98de3d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext import vocab, data\n",
        "\n",
        "from fastai.nlp import *\n",
        "from fastai.lm_rnn import *\n",
        "\n",
        "PATH='data/nietzsche/'\n",
        "\n",
        "TRN_PATH = 'trn/'\n",
        "VAL_PATH = 'val/'\n",
        "TRN = f'{PATH}{TRN_PATH}'\n",
        "VAL = f'{PATH}{VAL_PATH}'\n",
        "\n",
        "# Note: The student needs to practice her shell skills and prepare her own dataset before proceeding:\n",
        "# - trn/trn.txt (first 80% of nietzsche.txt)\n",
        "# - val/val.txt (last 20% of nietzsche.txt)\n",
        "\n",
        "%ls {PATH}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mmodels\u001b[0m/  nietzsche.txt  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b0vQyn5GsLhn",
        "colab_type": "code",
        "outputId": "a05dd466-2e0f-4a7a-953b-e95023157847",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%ls {PATH}trn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trn.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6G2N8tIPsLhs",
        "colab_type": "code",
        "outputId": "da378e04-3fbc-481f-8c1c-a0039775c325",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower=True, tokenize=list)\n",
        "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
        "\n",
        "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
        "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
        "\n",
        "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(963, 56, 1, 493747)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "tnsVZkjusLh0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ]
    },
    {
      "metadata": {
        "id": "ZxNCgaFvsLh0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        self.vocab_size = vocab_size\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6A-qxezlsLh5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RRXcyEwsLh9",
        "colab_type": "code",
        "outputId": "a9fc0320-1bff-4587-ed16-e24018663af8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a9e0a39ef174c72bac575be7e20579c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.81983  1.81247]                                 \n",
            "[ 1.       1.63097  1.66228]                                 \n",
            "[ 2.       1.54433  1.57824]                                 \n",
            "[ 3.       1.48563  1.54505]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TxBL2pFxsLiG",
        "colab_type": "code",
        "outputId": "f7920295-fa88-42e3-bf6e-990bd75fca77",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)\n",
        "\n",
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b15bf8bcc7445e694dbcb3beb658b74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.4187   1.50374]                                 \n",
            "[ 1.       1.41492  1.49391]                                 \n",
            "[ 2.       1.41001  1.49339]                                 \n",
            "[ 3.       1.40756  1.486  ]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X-0kBDWVsLia",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN loop"
      ]
    },
    {
      "metadata": {
        "id": "Q_kfFy95sLic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From the pytorch source\n",
        "\n",
        "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nwMIHKt8sLij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulRnn2(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp = []\n",
        "        o = self.h\n",
        "        for c in cs: \n",
        "            o = self.rnn(self.e(c), o)\n",
        "            outp.append(o)\n",
        "        outp = self.l_out(torch.stack(outp))\n",
        "        self.h = repackage_var(o)\n",
        "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcRJYdhzsLis",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdxC8P3bsLiy",
        "colab_type": "code",
        "outputId": "32d48550-9552-4cec-88eb-a22e75f9f273",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c46f24bfa194e1ba9d73e22283ca6af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.81013  1.7969 ]                                 \n",
            "[ 1.       1.62515  1.65346]                                 \n",
            "[ 2.       1.53913  1.58065]                                 \n",
            "[ 3.       1.48698  1.54217]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-EMhG0GqsLi_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ]
    },
    {
      "metadata": {
        "id": "IDUoy4ctsLjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uM3Mi3AtsLjF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From the pytorch source code - for reference\n",
        "\n",
        "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    gi = F.linear(input, w_ih, b_ih)\n",
        "    gh = F.linear(hidden, w_hh, b_hh)\n",
        "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
        "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
        "\n",
        "    resetgate = F.sigmoid(i_r + h_r)\n",
        "    inputgate = F.sigmoid(i_i + h_i)\n",
        "    newgate = F.tanh(i_n + resetgate * h_n)\n",
        "    return newgate + inputgate * (hidden - newgate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0IVySd3SsLjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
        "\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5kIb2ZV6sLjc",
        "colab_type": "code",
        "outputId": "5f259b38-2db8-45f2-a9df-1535a1e626a0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 6, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e518384d71c345a8b145b35d4ee894fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.68409  1.67784]                                 \n",
            "[ 1.       1.49813  1.52661]                                 \n",
            "[ 2.       1.41674  1.46769]                                 \n",
            "[ 3.       1.36359  1.43818]                                 \n",
            "[ 4.       1.33223  1.41777]                                 \n",
            "[ 5.       1.30217  1.40511]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lPEDLHwvsLji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBKgb7GzsLjp",
        "colab_type": "code",
        "outputId": "b9bd2e51-ca19-4f5e-a9e9-a8b8c2630c70",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 3, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be385370c27f4b788920caf48f90aeea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.22708  1.36926]                                 \n",
            "[ 1.       1.21948  1.3696 ]                                 \n",
            "[ 2.       1.22541  1.36969]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5AA7XqYesLjy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Putting it all together: LSTM"
      ]
    },
    {
      "metadata": {
        "id": "SO9TF_tCsLj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import sgdr\n",
        "\n",
        "n_hidden=512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzO68Y-_sLj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
        "        super().__init__()\n",
        "        self.vocab_size,self.nl = vocab_size,nl\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs):\n",
        "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
        "                  V(torch.zeros(self.nl, bs, n_hidden)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "arbiV1wLsLj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
        "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cu0dvgvUsLkB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{PATH}models', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5bDAT7isLkS",
        "colab_type": "code",
        "outputId": "e9c068b8-6dbe-4b93-b974-c2ca316429ec",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 2, lo.opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6943ca600bbf4a49a0020b2467c2ddb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.72032  1.64016]                                 \n",
            "[ 1.       1.62891  1.58176]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KfikFCpPsLkl",
        "colab_type": "code",
        "outputId": "78e32e3a-8394-4f54-e45c-b79b6ad01484",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "765d0d78da6647d48276a638f70aeec9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.47969  1.4472 ]                                 \n",
            "[ 1.       1.51411  1.46612]                                 \n",
            "[ 2.       1.412    1.39909]                                 \n",
            "[ 3.       1.53689  1.48337]                                 \n",
            "[ 4.       1.47375  1.43169]                                 \n",
            "[ 5.       1.39828  1.37963]                                 \n",
            "[ 6.       1.34546  1.35795]                                 \n",
            "[ 7.       1.51999  1.47165]                                 \n",
            "[ 8.       1.48992  1.46146]                                 \n",
            "[ 9.       1.45492  1.42829]                                 \n",
            "[ 10.        1.42027   1.39028]                              \n",
            "[ 11.        1.3814    1.36539]                              \n",
            "[ 12.        1.33895   1.34178]                              \n",
            "[ 13.        1.30737   1.32871]                              \n",
            "[ 14.        1.28244   1.31518]                              \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mNrdiB1KsLkv",
        "colab_type": "code",
        "outputId": "29d1697a-ffbf-48dd-c325-f6e0479e430b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4394818ec37f4b419397628b7cc8b815",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.46053  1.43462]                                 \n",
            "[ 1.       1.51537  1.47747]                                 \n",
            "[ 2.       1.39208  1.38293]                                 \n",
            "[ 3.       1.53056  1.49371]                                 \n",
            "[ 4.       1.46812  1.43389]                                 \n",
            "[ 5.       1.37624  1.37523]                                 \n",
            "[ 6.       1.3173   1.34022]                                 \n",
            "[ 7.       1.51783  1.47554]                                 \n",
            "[ 8.       1.4921   1.45785]                                 \n",
            "[ 9.       1.44843  1.42215]                                 \n",
            "[ 10.        1.40948   1.40858]                              \n",
            "[ 11.        1.37098   1.36648]                              \n",
            "[ 12.        1.32255   1.33842]                              \n",
            "[ 13.        1.28243   1.31106]                              \n",
            "[ 14.        1.25031   1.2918 ]                              \n",
            "[ 15.        1.49236   1.45316]                              \n",
            "[ 16.        1.46041   1.43622]                              \n",
            "[ 17.        1.45043   1.4498 ]                              \n",
            "[ 18.        1.43331   1.41297]                              \n",
            "[ 19.        1.43841   1.41704]                              \n",
            "[ 20.        1.41536   1.40521]                              \n",
            "[ 21.        1.39829   1.37656]                              \n",
            "[ 22.        1.37001   1.36891]                              \n",
            "[ 23.        1.35469   1.35909]                              \n",
            "[ 24.        1.32202   1.34228]                              \n",
            "[ 25.        1.29972   1.32256]                              \n",
            "[ 26.        1.28007   1.30903]                              \n",
            "[ 27.        1.24503   1.29125]                              \n",
            "[ 28.        1.22261   1.28316]                              \n",
            "[ 29.        1.20563   1.27397]                              \n",
            "[ 30.        1.18764   1.27178]                              \n",
            "[ 31.        1.18114   1.26694]                              \n",
            "[ 32.        1.44344   1.42405]                              \n",
            "[ 33.        1.43344   1.41616]                              \n",
            "[ 34.        1.4346    1.40442]                              \n",
            "[ 35.        1.42152   1.41359]                              \n",
            "[ 36.        1.42072   1.40835]                              \n",
            "[ 37.        1.41732   1.40498]                              \n",
            "[ 38.        1.41268   1.395  ]                              \n",
            "[ 39.        1.40725   1.39433]                              \n",
            "[ 40.        1.40181   1.39864]                              \n",
            "[ 41.        1.38621   1.37549]                              \n",
            "[ 42.        1.3838    1.38587]                              \n",
            "[ 43.        1.37644   1.37118]                              \n",
            "[ 44.        1.36287   1.36211]                              \n",
            "[ 45.        1.35942   1.36145]                              \n",
            "[ 46.        1.34712   1.34924]                              \n",
            "[ 47.        1.32994   1.34884]                              \n",
            "[ 48.        1.32788   1.33387]                              \n",
            "[ 49.        1.31553   1.342  ]                              \n",
            "[ 50.        1.30088   1.32435]                              \n",
            "[ 51.        1.28446   1.31166]                              \n",
            "[ 52.        1.27058   1.30807]                              \n",
            "[ 53.        1.26271   1.29935]                              \n",
            "[ 54.        1.24351   1.28942]                              \n",
            "[ 55.        1.23119   1.2838 ]                              \n",
            "[ 56.        1.2086    1.28364]                              \n",
            "[ 57.        1.19742   1.27375]                              \n",
            "[ 58.        1.18127   1.26758]                              \n",
            "[ 59.        1.17475   1.26858]                              \n",
            "[ 60.        1.15349   1.25999]                              \n",
            "[ 61.        1.14718   1.25779]                              \n",
            "[ 62.        1.13174   1.2524 ]                              \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EZ0WXxl5sLk2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0p9lUNJssLk6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test"
      ]
    },
    {
      "metadata": {
        "id": "YFzohTMAsLk8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = TEXT.numericalize(inp)\n",
        "    p = m(VV(idxs.transpose(0,1)))\n",
        "    r = torch.multinomial(p[-1].exp(), 1)\n",
        "    return TEXT.vocab.itos[to_np(r)[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2CMxzFnwsLk_",
        "colab_type": "code",
        "outputId": "46f86c61-39ef-4317-ae28-d14d1b22e1ad",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "metadata": {
        "id": "Ji_Sf0NKsLlR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-TfsCuEsLln",
        "colab_type": "code",
        "outputId": "fbe28afd-8bce-4d1a-c07b-d59e74135978",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(get_next_n('for thos', 400))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for those the skemps), or\n",
            "imaginates, though they deceives. it should so each ourselvess and new\n",
            "present, step absolutely for the\n",
            "science.\" the contradity and\n",
            "measuring, \n",
            "the whole!\n",
            "\n",
            "293. perhaps, that every life a values of blood\n",
            "of\n",
            "intercourse when it senses there is unscrupulus, his very rights, and still impulse, love?\n",
            "just after that thereby how made with the way anything, and set for harmless philos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3SKXRtCEsLlu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}